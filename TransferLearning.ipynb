{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer Learning for AI Text Detection\n",
        "\n",
        "Fine-tuning SOTA AI text detection models (`fakespot-ai/roberta-base-ai-text-detection-v1`) on the Mercor AI Detection dataset.\n",
        "\n",
        "## Approach\n",
        "- Uses pretrained AI text detection model specifically trained for this task\n",
        "- Custom ANN classifier head for improved performance\n",
        "- Combines topic + answer in input format\n",
        "- Upsamples minority class for balanced training\n",
        "- Comprehensive evaluation with ROC curves, PR curves, and confusion matrices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
            "\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/trainer.py:41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     42\u001b[0m     get_reporting_integration_callbacks,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     AutoTokenizer,\n\u001b[1;32m     27\u001b[0m     AutoConfig,\n\u001b[1;32m     28\u001b[0m     AutoModelForSequenceClassification,\n\u001b[1;32m     29\u001b[0m     DataCollatorWithPadding,\n\u001b[1;32m     30\u001b[0m     TrainingArguments,\n\u001b[1;32m     31\u001b[0m     Trainer,\n\u001b[1;32m     32\u001b[0m     EarlyStoppingCallback,\n\u001b[1;32m     33\u001b[0m     logging \u001b[38;5;28;01mas\u001b[39;00m transformers_logging\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Set style\u001b[39;00m\n",
            "File \u001b[0;32m<frozen importlib._bootstrap>:1229\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
            "File \u001b[0;32m~/Desktop/.conda/lib/python3.11/site-packages/transformers/utils/import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import warnings\n",
        "import time\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, \n",
        "    roc_curve, auc, precision_recall_curve\n",
        ")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        "    logging as transformers_logging\n",
        ")\n",
        "from datasets import Dataset\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Settings\n",
        "SEED = 42\n",
        "MODEL_NAME = \"fakespot-ai/roberta-base-ai-text-detection-v1\"\n",
        "MAX_LEN = 512\n",
        "PER_DEVICE_TRAIN_BATCH = 16  # Reduced for local training\n",
        "PER_DEVICE_EVAL_BATCH = 16\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "FP16 = False  # Set to True if using CUDA\n",
        "OUTPUT_DIR = \"./finetuned_roberta_ann_topic_answer\"\n",
        "PLOT_DIR = \"./plots\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(PLOT_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Reproducibility\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "transformers_logging.set_verbosity_error()\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "print(\"✓ Imports successful\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if hasattr(torch.backends, 'mps'):\n",
        "    print(f\"MPS available: {torch.backends.mps.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "def clean_text_field(s):\n",
        "    \"\"\"Clean text field by removing extra whitespace and newlines.\"\"\"\n",
        "    if pd.isna(s):\n",
        "        return \"\"\n",
        "    return \" \".join(str(s).strip().replace(\"\\r\", \" \").replace(\"\\n\", \" \").split())\n",
        "\n",
        "\n",
        "def make_input_string(topic, answer):\n",
        "    \"\"\"Combine topic and answer into a formatted input string.\"\"\"\n",
        "    t = clean_text_field(topic)\n",
        "    a = clean_text_field(answer)\n",
        "    return f\"TOPIC: {t}\\n\\nANSWER: {a}\"\n",
        "\n",
        "\n",
        "print(\"✓ Helper functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Prepare Data\n",
        "to "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Train shape: {df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "# Validate required columns\n",
        "required = {\"topic\", \"answer\", \"is_cheating\"}\n",
        "if not required.issubset(df.columns):\n",
        "    raise ValueError(f\"train.csv must contain columns: {required}\")\n",
        "\n",
        "if \"id\" not in test_df.columns:\n",
        "    raise ValueError(\"test.csv must contain column 'id'\")\n",
        "\n",
        "# Build combined text field\n",
        "print(\"\\nCreating combined text field (TOPIC + ANSWER)...\")\n",
        "df[\"text\"] = df.apply(lambda r: make_input_string(r[\"topic\"], r[\"answer\"]), axis=1)\n",
        "df[\"label\"] = df[\"is_cheating\"].astype(int)\n",
        "test_df[\"text\"] = test_df.apply(lambda r: make_input_string(r.get(\"topic\", \"\"), r.get(\"answer\", \"\")), axis=1)\n",
        "\n",
        "print(f\"\\nOriginal class distribution:\")\n",
        "print(df[\"label\"].value_counts().to_dict())\n",
        "print(f\"Class percentages:\")\n",
        "print(df[\"label\"].value_counts(normalize=True) * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "s "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upsample minority class = 0\n",
        "counts = df[\"label\"].value_counts().to_dict()\n",
        "print(\"Original label counts:\", counts)\n",
        "\n",
        "target_label = 0  # Upsample minority class 0\n",
        "majority_count = df[\"label\"].value_counts().max()\n",
        "minor_count = df[df[\"label\"] == target_label].shape[0]\n",
        "\n",
        "if minor_count == 0:\n",
        "    raise ValueError(f\"No samples with label {target_label}, cannot upsample.\")\n",
        "\n",
        "if minor_count < majority_count:\n",
        "    needed = majority_count - minor_count\n",
        "    minority_df = df[df[\"label\"] == target_label]\n",
        "    extra = minority_df.sample(n=needed, replace=True, random_state=SEED)\n",
        "    df_ups = pd.concat([df, extra], ignore_index=True).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "    print(f\"\\n✓ Upsampled label={target_label}: +{needed} samples\")\n",
        "    print(f\"New counts: {df_ups['label'].value_counts().to_dict()}\")\n",
        "    df = df_ups\n",
        "else:\n",
        "    print(\"\\nNo upsampling needed (minority already >= majority).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train/Validation Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Val split (stratified)\n",
        "train_df, val_df = train_test_split(\n",
        "    df[[\"text\", \"label\"]],\n",
        "    test_size=0.20,\n",
        "    random_state=SEED,\n",
        "    stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}\")\n",
        "print(\"Post-split label counts (train):\", train_df[\"label\"].value_counts().to_dict())\n",
        "\n",
        "# Save CSVs for reproducibility (optional)\n",
        "train_df.to_csv(\"train_for_finetune.csv\", index=False)\n",
        "val_df.to_csv(\"val_for_finetune.csv\", index=False)\n",
        "print(\"\\n✓ Saved train_for_finetune.csv and val_for_finetune.csv\")\n",
        "\n",
        "# Convert to HuggingFace Datasets\n",
        "train_ds = Dataset.from_pandas(train_df)\n",
        "val_ds = Dataset.from_pandas(val_df)\n",
        "test_ds = Dataset.from_pandas(test_df[[\"id\", \"text\"]].rename(columns={\"id\": \"orig_id\"}))\n",
        "\n",
        "print(f\"\\n✓ Created HuggingFace datasets\")\n",
        "print(f\"  Train: {len(train_ds)} samples\")\n",
        "print(f\"  Val: {len(val_ds)} samples\")\n",
        "print(f\"  Test: {len(test_ds)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model and Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tokenizer and model\n",
        "print(f\"Loading model: {MODEL_NAME}\")\n",
        "print(\"This may take a few minutes on first run...\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
        "config.num_labels = 2\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=config)\n",
        "\n",
        "print(f\"✓ Model loaded: {MODEL_NAME}\")\n",
        "print(f\"  Hidden size: {model.config.hidden_size}\")\n",
        "print(f\"  Number of labels: {config.num_labels}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "t "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom ANN Head for classification\n",
        "hidden_size = model.config.hidden_size\n",
        "\n",
        "class ANNHead(nn.Module):\n",
        "    \"\"\"Custom Artificial Neural Network head for classification.\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size, inner_dim=768, dropout_prob=0.25):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hidden_size, inner_dim)\n",
        "        self.act = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "        self.fc2 = nn.Linear(inner_dim, max(128, inner_dim//2))\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout_prob)\n",
        "        self.out = nn.Linear(max(128, inner_dim//2), 2)  # 2 labels\n",
        "        \n",
        "        # Initialize weights\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.constant_(self.fc1.bias, 0.0)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.constant_(self.fc2.bias, 0.0)\n",
        "        nn.init.xavier_uniform_(self.out.weight)\n",
        "        nn.init.constant_(self.out.bias, 0.0)\n",
        "    \n",
        "    def forward(self, features):\n",
        "        \"\"\"\n",
        "        Accepts either:\n",
        "         - features shape (batch, hidden) -> pooled representations\n",
        "         - features shape (batch, seq_len, hidden) -> sequence output (pick CLS token)\n",
        "        \"\"\"\n",
        "        if features.dim() == 3:\n",
        "            # Pick CLS token (Roberta-style)\n",
        "            features = features[:, 0, :]\n",
        "        \n",
        "        x = self.fc1(features)\n",
        "        x = self.act(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "# Replace classifier head with custom ANN\n",
        "inner_dim = min(1024, hidden_size * 2)\n",
        "if hasattr(model, \"classifier\"):\n",
        "    model.classifier = ANNHead(hidden_size, inner_dim=inner_dim, dropout_prob=0.25)\n",
        "else:\n",
        "    model.classifier = ANNHead(hidden_size, inner_dim=inner_dim, dropout_prob=0.25)\n",
        "\n",
        "print(f\"✓ Replaced classifier with custom ANN head\")\n",
        "print(f\"  Hidden size: {hidden_size}\")\n",
        "print(f\"  Inner dimension: {inner_dim}\")\n",
        "\n",
        "# Disable cache for training\n",
        "try:\n",
        "    model.config.use_cache = False\n",
        "    if hasattr(model, \"model\") and hasattr(model.model, \"config\"):\n",
        "        model.model.config.use_cache = False\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"✓ Model moved to device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenize Datasets\n",
        "bench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize datasets\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
        "\n",
        "print(\"Tokenizing train dataset...\")\n",
        "train_ds = train_ds.map(tokenize_batch, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "print(\"Tokenizing val dataset...\")\n",
        "val_ds = val_ds.map(tokenize_batch, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "print(\"Tokenizing test dataset...\")\n",
        "test_ds = test_ds.map(\n",
        "    lambda b: tokenizer(b[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN),\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "# Rename label column for Trainer\n",
        "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
        "val_ds = val_ds.rename_column(\"label\", \"labels\")\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_ds.set_format(type=\"torch\")\n",
        "val_ds.set_format(type=\"torch\")\n",
        "test_ds.set_format(type=\"torch\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "print(\"✓ Datasets tokenized and formatted\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.softmax(torch.from_numpy(logits), dim=1).numpy()[:, 1]\n",
        "    try:\n",
        "        auc_score = roc_auc_score(labels, probs)\n",
        "    except Exception:\n",
        "        auc_score = 0.5\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    acc = (preds == labels).mean()\n",
        "    return {\"roc_auc\": auc_score, \"accuracy\": float(acc)}\n",
        "\n",
        "print(\"✓ Metrics function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"roc_auc\",\n",
        "    greater_is_better=True,\n",
        "    per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH,\n",
        "    per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    fp16=FP16,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    seed=SEED,\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=2)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "print(\"✓ Trainer configured\")\n",
        "print(f\"  Training batch size: {PER_DEVICE_TRAIN_BATCH}\")\n",
        "print(f\"  Eval batch size: {PER_DEVICE_EVAL_BATCH}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"  Max epochs: {NUM_EPOCHS}\")\n",
        "print(f\"  Early stopping patience: 2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model\n",
        "print(\"Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "t0 = time.time()\n",
        "train_result = trainer.train()\n",
        "t1 = time.time()\n",
        "\n",
        "duration_min = (t1 - t0) / 60.0\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Training completed in {duration_min:.2f} minutes\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Save final model + tokenizer\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"\\n✓ Model saved to {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate on Validation Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on validation set\n",
        "eval_result = trainer.evaluate(eval_dataset=val_ds)\n",
        "print(\"Evaluation result:\")\n",
        "print(eval_result)\n",
        "\n",
        "# Get predictions for validation set\n",
        "preds_out = trainer.predict(val_ds)\n",
        "logits = preds_out.predictions\n",
        "probs = torch.softmax(torch.from_numpy(logits), dim=1).numpy()[:, 1]\n",
        "labels = preds_out.label_ids\n",
        "\n",
        "# Calculate ROC-AUC\n",
        "fpr, tpr, _ = roc_curve(labels, probs)\n",
        "roc_auc_val = auc(fpr, tpr)\n",
        "print(f\"\\nValidation ROC-AUC: {roc_auc_val:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC curve\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_val:.4f})')\n",
        "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Validation ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig(os.path.join(PLOT_DIR, \"val_roc_curve.png\"), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(labels, probs)\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.plot(recall, precision, label=\"PR curve\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Validation Precision-Recall Curve\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig(os.path.join(PLOT_DIR, \"val_pr_curve.png\"), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix (threshold 0.5)\n",
        "preds_bin = (probs >= 0.5).astype(int)\n",
        "cm = confusion_matrix(labels, preds_bin)\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=[0, 1])\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Validation Confusion Matrix\")\n",
        "plt.savefig(os.path.join(PLOT_DIR, \"val_confusion_matrix.png\"), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"✓ Validation plots saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training History Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training log visualization\n",
        "log_history = trainer.state.log_history\n",
        "if log_history:\n",
        "    df_logs = pd.DataFrame(log_history)\n",
        "    df_logs = df_logs[df_logs[\"epoch\"].notna()]\n",
        "    \n",
        "    if not df_logs.empty:\n",
        "        # Loss curves\n",
        "        plt.figure(figsize=(9, 4))\n",
        "        if \"loss\" in df_logs.columns:\n",
        "            plt.plot(df_logs[\"epoch\"], df_logs[\"loss\"], marker=\"o\", label=\"train_loss\")\n",
        "        if \"eval_loss\" in df_logs.columns:\n",
        "            plt.plot(df_logs[\"epoch\"], df_logs[\"eval_loss\"], marker=\"o\", label=\"eval_loss\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Training / Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.savefig(os.path.join(PLOT_DIR, \"losses.png\"), dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # ROC-AUC by epoch\n",
        "        if \"eval_roc_auc\" in df_logs.columns:\n",
        "            plt.figure(figsize=(9, 4))\n",
        "            plt.plot(df_logs[\"epoch\"], df_logs[\"eval_roc_auc\"], marker=\"o\", label=\"eval_roc_auc\")\n",
        "            plt.xlabel(\"Epoch\")\n",
        "            plt.ylabel(\"ROC-AUC\")\n",
        "            plt.title(\"Validation ROC-AUC by Epoch\")\n",
        "            plt.legend()\n",
        "            plt.grid(alpha=0.3)\n",
        "            plt.savefig(os.path.join(PLOT_DIR, \"val_roc_by_epoch.png\"), dpi=150, bbox_inches='tight')\n",
        "            plt.show()\n",
        "\n",
        "print(\"✓ Training history plots saved\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Validation Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save validation predictions\n",
        "val_out = val_df.copy()\n",
        "val_out[\"pred_prob_ai\"] = probs\n",
        "val_out[\"pred_label\"] = preds_bin\n",
        "val_out.to_csv(\"val_predictions_with_probs.csv\", index=False)\n",
        "print(\"✓ Saved val_predictions_with_probs.csv\")\n",
        "print(f\"\\nValidation predictions summary:\")\n",
        "print(val_out[[\"label\", \"pred_prob_ai\", \"pred_label\"]].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on Test Set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "print(f\"Tokenized test set size: {len(test_ds)}\")\n",
        "print(\"Predicting on test set...\")\n",
        "\n",
        "test_preds = trainer.predict(test_ds)\n",
        "test_logits = test_preds.predictions\n",
        "test_probs = torch.softmax(torch.from_numpy(test_logits), dim=1).numpy()[:, 1]\n",
        "\n",
        "# Retrieve original ids from test_df\n",
        "ids = test_df[\"id\"].tolist()\n",
        "if len(ids) != len(test_probs):\n",
        "    # Fallback: use orig_id from test_ds if available\n",
        "    if \"orig_id\" in test_ds.column_names:\n",
        "        ids = test_ds[\"orig_id\"]\n",
        "    else:\n",
        "        ids = list(range(len(test_probs)))\n",
        "\n",
        "# Create submission\n",
        "submission_df = pd.DataFrame({\"id\": ids, \"is_cheating\": test_probs})\n",
        "submission_csv = \"submission_transfer_learning.csv\"\n",
        "submission_df.to_csv(submission_csv, index=False)\n",
        "\n",
        "print(f\"✓ Saved submission to {submission_csv} ({len(submission_df)} rows)\")\n",
        "print(f\"\\nSubmission statistics:\")\n",
        "print(submission_df[\"is_cheating\"].describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Set Probability Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot test distribution\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(test_probs, bins=50, kde=True)\n",
        "plt.title(\"Test Set Predicted Probability Distribution (is_cheating)\", fontweight='bold')\n",
        "plt.xlabel(\"Predicted Probability\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig(os.path.join(PLOT_DIR, \"test_prob_dist.png\"), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ALL DONE!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"✓ Model trained and evaluated\")\n",
        "print(f\"✓ Plots saved in {PLOT_DIR}\")\n",
        "print(f\"✓ Submission saved: {submission_csv}\")\n",
        "print(f\"✓ Model saved: {OUTPUT_DIR}\")\n",
        "print(f\"\\nFinal Validation ROC-AUC: {roc_auc_val:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
